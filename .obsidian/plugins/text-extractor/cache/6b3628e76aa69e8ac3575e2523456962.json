{"path":".obsidian/plugins/text-extractor/cache/6b3628e76aa69e8ac3575e2523456962.json","text":"Different feature selection criteric * Information Gain prefers features with many labels as it will split the data into small subsets, which will tend to be pure, irrespective of any correlation between the feature and the target. * Information Gain Ratio: * Divide the IG of a feature d by the amount of information used to determine the value of the feature (i.e. the entropy of the dataset wrt the feature d) . GR(d,D) = $ . - (P(d =) x foga(P(d = 1)) * GR addresses the bias IG has toyfart g)features with 1qarge numbers of values as the divisor biases away from these types of features nTg bR","libVersion":"0.2.2","langs":"eng"}