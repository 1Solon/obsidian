## Overview

Model selection is a critical step in the machine learning pipeline, focusing not just on choosing the right algorithm (e.g., k-NN, Decision Trees, Na√Øve Bayes) but also on selecting appropriate pre-processing steps, and fine-tuning model hyperparameters.

### Key Components

- **Pipeline**: Automates and sequences the pre-processing steps and model training. For example, combining a `StandardScaler` with a classifier in a sequence ensures data normalization before training.
- **Grid Search**: Systematically explores multiple combinations of model parameters (or hyperparameters), finding the set that produces the best results, typically measured in accuracy or another performance metric.

### Hyperparameters vs. Model Parameters

- **Model Parameters**: Learned from data, such as weights in neural networks or coefficients in linear models.
- **Hyperparameters**: Set before training and guide the learning process (e.g., `k` in k-NN, `max_depth` in Decision Trees).

### Pre-processing Example: Imputation

Pre-processing steps, such as imputation of missing values, should not incorporate information from the test set. Using tools like `SimpleImputer` or `KNNImputer`, it's crucial to fit these only on training data to prevent data leakage.

### Correct Data Splitting and Pipelining

- **The Wrong Way**: Applying pre-processing steps before splitting the data into training and testing sets.
- **The Right Way**: Split the data first, then apply pre-processing steps within a pipeline that ensures test data remains unseen by the imputer or scaler.

### Pipelines: Enhancing Model Training and Evaluation

Pipelines encapsulate a sequence of data processing steps and the model training process into a single object. This approach simplifies the code, prevents mistakes like data leakage, and makes it easy to experiment with different pre-processing steps or model hyperparameters.

### Hyperparameter Tuning: Grid Search

Grid Search evaluates a model with every combination of a predefined list of hyperparameters, selecting the combination that performs the best. It's a powerful tool for model optimization but can be computationally expensive.

### Alternatives and Enhancements

- **Randomized Search**: Offers a more computationally efficient alternative by randomly sampling a subset of the parameter space.
- **Cross-Validation**: Evaluating model performance using cross-validation within grid search ensures the selection of hyperparameters generalizes well to unseen data.

### Practical Tips

- When using pipelines and grid search, ensure that test data does not influence the fitting of any pre-processing steps.
- Consider the computational cost of grid search and explore randomized search for very large hyperparameter spaces.

### Summary

Model selection involves choosing the right model, pre-processing steps, and hyperparameters. Using pipelines and tools like grid search, practitioners can automate and systematically explore the best configurations for their models.

---
* [[ML Lecture 7]]

