## The Big Idea

Artificial Neural Networks (ANNs) draw inspiration from the human brain's structure and function, utilizing a network of neurons to process and transmit signals for complex decision-making.

### Key Components

- **Neurons**: Basic computational units that receive, process, and transmit information. Each neuron can perform simple signal processing tasks, aggregating inputs to produce a meaningful output.
- **Synapses**: Connections between neurons that allow them to communicate. The strength of these connections, or weights, determines the influence of one neuron on another.

### Understanding ANNs

- ANNs consist of layers of interconnected neurons: an input layer, one or more hidden layers, and an output layer. Information flows from the input to the output layer, often without cycles (feedforward networks).
- **Activation Functions**: Functions that determine a neuron's output based on its input. Common examples include the sigmoid, ReLU (rectified linear unit), and softmax functions.

### Model Decision Making

- Decision-making in ANNs involves weighting input signals and applying activation functions to determine outputs. This process allows ANNs to make predictions or classifications based on input data.

### Challenges and Solutions

- ANNs can model complex, non-linear relationships and patterns in data. However, designing an effective network architecture requires careful consideration of the number of layers, neuron count, and the choice of activation functions.
- **Overfitting**: A common challenge where a model learns the training data too well, including its noise, leading to poor generalization. Techniques to combat overfitting include regularization (adding a penalty for large weights) and adjusting network complexity.

### Training ANNs

- **Backpropagation**: A key algorithm for training ANNs, allowing error information from the output layer to propagate backwards through the network to update weights.
- **Gradient Descent**: A method used alongside backpropagation to adjust neuron weights in the direction that minimizes the overall error or loss of the network.

### Practical Applications

- ANNs excel in tasks requiring the modelling of complex relationships, such as image recognition, natural language processing, and more. Their ability to learn from data makes them versatile tools for a wide range of applications.

### Considerations

- **Initialization and Tuning**: The initialization of weights and the tuning of hyperparameters (like learning rate) are crucial for the successful training of an ANN.
- **Architecture Design**: The choice of architecture—how many layers and neurons, and what types of layers to use—is vital for capturing the complexity of the data without overfitting.

### Summary

Neural Networks represent a powerful class of machine learning models capable of learning from complex and high-dimensional data. Their design, inspired by the biological neural networks in the brain, allows for the modelling of complex patterns and relationships, making them suitable for a wide range of applications from simple classification to sophisticated image and speech recognition tasks.

---
* [[ML Lecture 7]]
