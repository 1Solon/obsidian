![[Pasted image 20240208113824.png]]
> * Preference Bias: Choose decision trees that have fewer tests, i.e. shallower trees * Pure nodes provide more information about the value of the target feature for a query. * Descriptive features that split the dataset into pure sets provide information about the target feature and are considered more informative. * Testing the informative features early on in the tree can result in shallower trees. * Claude Shannonâ€™s entropy model is a computational metric of the purity of a set. T

## Links
---
* [[Entropy]]